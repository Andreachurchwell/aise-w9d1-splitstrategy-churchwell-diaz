<p align="center">
  <img src="assets/cJtc.png" alt="Justice Through Code Banner" width="500"/>
</p>

<p align="center">
  <img src="assets/jtc.png" alt="JTC Icon" width="90"/>
</p>

<h1 align="center">ğŸ§ª AISE Week 9 â€” Split Strategy Showdown</h1>
<h3 align="center">Team: Andrea Churchwell & Jose Diaz</h3>

<p align="center">
  <img src="https://img.shields.io/badge/AISE-2025-blueviolet?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Week-9-informational?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Status-In%20Progress-yellow?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Dataset-Diabetes-orange?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Metric-RÂ²-success?style=for-the-badge"/>
</p>
## â¤ï¸ Why We Chose the Diabetes Dataset

We selected the Diabetes Regression dataset (#7) not just because it fits the Week 9 assignment requirements, but because the topic is personally meaningful to both of us. JosÃ©'s mother has lived with diabetes for years, and Andreaâ€™s beloved cocker spaniel, Ace, also developed diabetes later in life. Working with this dataset feels more impactful and motivating since it represents a condition that has touched both of our lives. Even though this is a simple machine learning evaluation assignment, using a dataset connected to real people (and pets) we care about makes the project feel more grounded and important.

---

## ğŸ“Œ Project Overview
This repository contains our team implementation for the AISE 26 W9D1 Split Strategy Showdown.
Our goal is to compare different evaluation strategies on the same dataset, using the same model and the same metric, and analyze how each strategy impacts stability, variance, and trustworthiness.

We are now mid-way through Part A development, with the environment fully working and Partner Aâ€™s Jupyter workflow set up correctly.

---

## âœ… Current Progress

### âœ” Repository + Structure Ready
- GitHub repo initialized  
- .gitignore created  
- Required scaffold files added:
  - TEAM_INFO.md
  - eval_partner_a.py
  - eval_partner_b.py
  - comparison.csv
  - RECOMMENDATION.md

### âœ” Virtual Environment Working
- venv/ successfully created  
- All dependencies installed  
- Jupyter kernel connected inside VS Code (aise_w9d1_venv)

### âœ” Jupyter Notebook Working
- partner_a_notebook.ipynb created  
- Imports, dataset loading, splitting all verified working

### âœ” Dataset Selected
**Dataset #7 â€” Diabetes Regression Dataset**

### âœ” Metric Selected
**RÂ² (Coefficient of Determination)**

### âœ” Partner A Code Completed (Functionally)
- Data loaded and explored  
- 80/20 Random Holdout implemented  
- Ridge Regression + StandardScaler pipeline  
- Test RÂ² score printed  
- 5-fold KFold CV implemented  
- CV mean + std printed  

---

## â³ Next Steps
### ğŸ”¸ 1. Partner B (JosÃ©)
Implement evaluation using:
- same dataset  
- same metric (RÂ²)  
- stratified or specialized CV (based on assignment instructions)

### ğŸ”¸ 2. Fill in TEAM_INFO.md
Add:
- names & roles  
- dataset (#7)  
- metric (RÂ²)  
- why we chose this dataset  
- code block for loading diabetes dataset  
- package versions

### ğŸ”¸ 3. Populate comparison.csv
After both scripts run, record:
- test score  
- CV mean  
- CV std  
- fold-by-fold results  
for Partner A and Partner B.

### ğŸ”¸ 4. Write RECOMMENDATION.md
Final 200â€“250 word analysis comparing:
- variance  
- stability  
- leakage risk  
- which strategy we'd trust  

---

## ğŸš€ Project Status

| Step                     | Status      |
|--------------------------|------------ |
| Repo created             | âœ… Done    |
| venv + requirements.txt  | âœ… Done    |
| Jupyter kernel fixed     | âœ”ï¸ Done    |
| Dataset selected (#7)    | âœ”ï¸ Done    |
| Metric selected (RÂ²)     | âœ”ï¸ Done    |
| Partner A code           | âœ”ï¸ Done    |
| Partner B code           | â³ Pending |
| comparison.csv           | â³ Pending |
| TEAM_INFO.md             | â³ Pending |
| RECOMMENDATION.md        | â³ Pending |


---

## ğŸ“ Notes

This README will continue evolving as we finalize the dataset and metric and begin implementing the required evaluation strategies.


